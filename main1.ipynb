{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.16"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python2716jvsc74a57bd0767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90",
   "display_name": "Python 2.7.16 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('./archive/satellite.mat.csv')\n",
    "\n",
    "# Generally look at what data points and types there are, and see if there is any missing\n",
    "print('DF Shape: \\n', df.shape)\n",
    "print('DF head: \\n', df.head())\n",
    "print('DF with data types: \\n', df.info())\n",
    "print('DF with empty values: \\n', df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore means, variances (sqaured root ie. std) and quantiles of column features, and boxplot\n",
    "fig, ax = plt.subplots(figsize=(25, 4))\n",
    "df.iloc[:,1:-1].boxplot()\n",
    "df.iloc[:,1:-1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore features trend over time\n",
    "\n",
    "pos_idx = (df.Y == 1)\n",
    "neg_idx = (df.Y < 1)\n",
    "\n",
    "def plot_time_series(chart_name: str, target_idx: any, features: list, last_n_steps: int = 1000):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 3))\n",
    "    df_ts = df.copy()\n",
    "    df_ts[target_idx] = None\n",
    "\n",
    "    chart_name += ' ({})'.format(','.join(features))\n",
    "\n",
    "    for f in features:\n",
    "        if ax:\n",
    "            df_ts.iloc[-last_n_steps:,].plot.scatter(x='ID', y=f, title='Feature Historical Trend - {}'.format(chart_name), s=1, c='blue', ax=ax)\n",
    "        else:\n",
    "            ax = df_ts.iloc[-last_n_steps:,].plot.scatter(x='ID', y=f, title='Feature Historical Trend - {}'.format(chart_name), s=1, c='blue')\n",
    "\n",
    "    ax.set_ylabel('Features')\n",
    "    del df_ts\n",
    "\n",
    "def plot_dist(features: list):\n",
    "    for f in features:\n",
    "        sns.displot(df, x=f, hue='Y', kind='kde', fill=True)\n",
    "    \n",
    "plot_time_series('Positive Event Occured', pos_idx, ['V1', 'V2', 'V3', 'V4'])\n",
    "plot_time_series('No Positive Event Occured', neg_idx, ['V1', 'V2', 'V3', 'V4'])\n",
    "plot_dist(['V1', 'V2', 'V3', 'V4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore linear relationship between a predictor (feature) and response using covariance\n",
    "# *(Note that the magnitude of covariance means NOTHING since predictors are not normalised and THUS a predictor with higher scale will give larger covariance value regardless of if strong/weak relationships)\n",
    "sns.set(rc={'figure.figsize':(30,5)})\n",
    "covMatrix = pd.DataFrame.cov(df.iloc[:,1:])\n",
    "sns.heatmap([covMatrix['Y'].array], linewidths=.5, cmap='YlGnBu', annot=True, square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the ratio of variance between a predictor (feature) VS a response, to identify relevance between two using an ANOVA F-test (relevance between numerical input & cat output)\n",
    "\n",
    "# 'ANOVA' tests whether or not there are significant differences between the means of your independent varaibles (such as age, sex, income and stress level). This can be achieved with F-test by looking at F-value. \n",
    "# 'F-value' = (Sum of squared errors BETWEEN groups (group mean)/ degree of freedom) / (Sum of sqaured errors WITHIN groups / degree of freedom) \n",
    "# -> The high F-value means the variance of group means is higher than within groups (by group) meaning means between groups are varied\n",
    "# -> Reject the null hypothesis that the group means are equal BETWEEN groups\n",
    "\n",
    "# Distance between groups/compactness by group (when data points labelled by class)\n",
    "\n",
    "# More reading: https://machinelearningmastery.com/feature-selection-with-numerical-input-data/ & Example: Compare level of stress by different condition (https://www.youtube.com/watch?v=-yQb_ZJnFXw)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest # (Select Top N)\n",
    "from sklearn.feature_selection import f_classif # (ANOVA F-test)\n",
    "\n",
    "X = df.values[:,1:-1]\n",
    "y = df.values[:,-1]\n",
    "\n",
    "fs = SelectKBest(score_func=f_classif)\n",
    "fs.fit(X, y)\n",
    "X_new = fs.transform(X)\n",
    "\n",
    "# List scores of F-value by feature\n",
    "for i in range(len(fs.scores_)):\n",
    "    print('V%d -  F-value: %f, P-value: %.10f' % (i, fs.scores_[i], fs.pvalues_[i]))\n",
    "\n",
    "# Visualise them\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.show()\n",
    "\n",
    "# Select features by F-value (all p values seem below alpha level)\n",
    "feature_cols_selected = df.columns[fs.get_support(indices=True) + 1]\n",
    "print('Features Selected (ANOVA): \\n', feature_cols_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series('Positive Event Occured', pos_idx, list(feature_cols_selected))\n",
    "plot_time_series('No Positive Event Occured', neg_idx, list(feature_cols_selected))\n",
    "plot_dist(list(feature_cols_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise a dataset\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# (Reduce the effect of outliers)\n",
    "scaler = RobustScaler()\n",
    "X = scaler.fit_transform(df[feature_cols_selected].iloc[:,2:-1])\n",
    "\n",
    "# Split to train & test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the baseline model (Linear SVM)\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print('Training Data:\\n', Counter(y_train))\n",
    "\n",
    "clf = OneClassSVM(kernel='linear', gamma='auto', nu=0.7).fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model, and visualise in confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred = np.array([(0 if p < 0 else p) for p in y_pred])\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 0.9], # how many outliers we allow\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf', 'linear'] } # how far the influence of a single training example reaches\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, scoring='roc_auc', verbose=1) # (roc_aus considers both recall & precision and find balance)\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "# print('Grid Best Params:\\n', grid.best_params_)\n",
    "# print('Grid Best Estimator:\\n', grid.best_estimator_)\n",
    "\n",
    "# Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
    "# Grid Best Params:\n",
    "#  {'C': 0.7, 'gamma': 1, 'kernel': 'rbf'}\n",
    "# Grid Best Estimator:\n",
    "#  SVC(C=0.7, gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the tuned model\n",
    "clf = SVC(kernel='rbf', gamma=1, C=0.7).fit(X_train, y_train)\n",
    "print(clf.predict(X)) # (outlier labelled as -1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred = np.array([(0 if p < 0 else p) for p in y_pred])\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualise the RBF SVM \n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px  \n",
    "import plotly.graph_objects as go\n",
    "import plotly.graph_objects as graph_objects\n",
    "\n",
    "\n",
    "# Reduce dimensionality to 2 features with PCA to visualise in 2D space\n",
    "pca_2d = PCA(n_components=2).fit_transform(X_train)\n",
    "\n",
    "# Train the model\n",
    "clf_v = SVC(kernel='rbf', gamma=1, C=1, probability=True).fit(pca_2d, y_train)\n",
    "\n",
    "# Scatter plot for training data\n",
    "fig = px.scatter(x=pca_2d[:, 0], y=pca_2d[:, 1], color=y_train, opacity=.7, labels={'x': 'PCA Feature 1', 'y': 'PCA Feature 2'}, title='Scatter Plot & Decision Boundaries - Normal vs Anomaly Event')\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "fig.show()\n",
    "\n",
    "# Find the scale of x and y axes (ie. pca 2d features)\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# Generate data points in between the scales given\n",
    "xx = np.linspace(pca_2d[:, 0].min(), pca_2d[:, 0].max(), 20)\n",
    "yy = np.linspace(pca_2d[:, 1].min(), pca_2d[:, 1].max(), 20)\n",
    "\n",
    "# Prepare to find all the combinations between two\n",
    "XX, YY = np.meshgrid(xx, yy)\n",
    "\n",
    "# Ravel makes nd array become 1d array, and vstack finds all the pairs between given two arrays\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "z_y_pred = clf_v.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# Visualise predicted contours to draw decision boundaries\n",
    "fig.add_traces(go.Contour(x=xx, y=yy, z=z_y_pred, opacity=.6))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Visualise in 3D plot with a hyperplane\n",
    "y_pred = clf_v.predict_proba(np.c_[XX.ravel(), YY.ravel()])[:, 1]\n",
    "z_y_pred = y_pred.reshape(XX.shape)\n",
    "\n",
    "fig = px.scatter_3d(x=pca_2d[:, 0], y=pca_2d[:, 1], z=y_train, color=y_train, opacity=.8, labels={'x': 'PCA Feature 1', 'y': 'PCA Feature 2', 'z': 'Anomaly Event (Probability)'}, title='3D Scatter Plot & Hyperplane - Normal vs Anomaly Event')\n",
    "fig.update_traces(marker=dict(size=1))\n",
    "\n",
    "fig.add_traces(go.Surface(x=xx, y=yy, z=z_y_pred, name='SVM Prediction',\n",
    "                              colorscale='RdBu', showscale=False, \n",
    "                              contours = {\"z\": {\"show\": True, \"start\": -10, \"end\": 10, \"size\": 0.01}}))\n",
    "fig.update_layout(width=800, height=800)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}